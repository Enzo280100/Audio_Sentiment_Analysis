{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üìä **An√°lisis de Sentimiento Audios**\n",
    "**Autor:** Enzo Favian Infantes Zuniga \\\n",
    "**Rol:** Data Scientist | Economist \\\n",
    "**Correo:** enzo.infantes28@gmail.com \\\n",
    "**Fecha:** Noviembre 2025  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\einfantesz\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "main_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_dir = os.path.join(main_dir, 'data')\n",
    "audio_train_dir = os.path.join(data_dir, 'TRAIN')\n",
    "audio_test_dir = os.path.join(data_dir, 'TEST')\n",
    "\n",
    "audio_processed_dir = os.path.join(data_dir, 'processed')\n",
    "audio_processed_train_dir = os.path.join(audio_processed_dir, 'train')\n",
    "audio_processed_test_dir = os.path.join(audio_processed_dir, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Normalizaci√≥n del audio\n",
    "`AudioSegment`: Lee el archivo de audio y lo convierte en un objeto AudioSegment que puedes manipular. \\\n",
    "`set_frame_rate(1600)`: Cambia la frecuencia de muestreo a 16 kHz. Menos tama√±o y m√°s que necesario para voz humana (< 8kHz). \\\n",
    "`set_channels(1)`: Todo el sonido en una sola pista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(audio_train_dir) if f.lower().endswith('.wav')]\n",
    "\n",
    "for filename in tqdm(files, desc=\"Procesando audios\", unit=\"archivo\"):\n",
    "    input_path = os.path.join(audio_train_dir, filename)\n",
    "    output_path = os.path.join(audio_processed_train_dir, filename)\n",
    "\n",
    "    try:\n",
    "        print(f\"Procesando {filename}...\")\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "        audio.export(output_path, format=\"wav\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error con {filename}: {e}. Saltando...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Denoising | reducci√≥n de ruido\n",
    "\n",
    "`Librosa`: Lee el archivo de audio y lo convierte en un array NumPy (audio) y devuelve la frecuencia de muestreo (sr). \\\n",
    "`nr.reduce_noise`: Algoritmo de supresi√≥n de ruido. Aten√∫a las frecuencias correspondientes a ruido de fondo. \\\n",
    "`sf`: Guarda el archivo en formato *.wav*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(audio_processed_train_dir) if f.lower().endswith('.wav')]\n",
    "\n",
    "for filename in tqdm(files, desc=\"Procesando audios\", unit=\"archivo\"):\n",
    "    input_path = os.path.join(audio_processed_train_dir, filename)\n",
    "    output_path = os.path.join(audio_processed_train_dir, filename)\n",
    "\n",
    "    try:\n",
    "        print(f\"Procesando {filename}...\")\n",
    "        audio, sr = librosa.load(input_path, sr=16000)\n",
    "        reduced_noise = nr.reduce_noise(y=audio, sr=sr)\n",
    "        sf.write(output_path, reduced_noise, sr)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error con {filename}: {e}. Saltando...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Normalizaci√≥n de Volumen\n",
    "\n",
    "`librosa.util.normalize`: Ajusta la amplitud del audio para tener un rango consistente. Audios con una misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(audio_processed_train_dir) if f.lower().endswith('.wav')]\n",
    "\n",
    "for filename in tqdm(files, desc=\"Procesando audios\", unit=\"archivo\"):\n",
    "    input_path = os.path.join(audio_processed_train_dir, filename)\n",
    "    output_path = os.path.join(audio_processed_train_dir, filename)\n",
    "\n",
    "    try:\n",
    "        print(f\"Procesando {filename}...\")\n",
    "        normalized = librosa.util.normalize(input_path)\n",
    "        sf.write(output_path, normalized, sr)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error con {filename}: {e}. Saltando...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Detecci√≥n de voz\n",
    "\n",
    "Procesa todos los .wav en la carpeta indicada. Detecta voz con Silero VAD. Recorta los segmentos y los guarda en voz_segmentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\n",
    "(get_speech_timestamps, _, read_audio, _, _) = utils\n",
    "\n",
    "files = [f for f in os.listdir(audio_processed_train_dir) if f.lower().endswith('.wav')]\n",
    "\n",
    "output_dir = os.path.join(audio_processed_train_dir, \"voz_segmentos\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(files, desc=\"Procesando audios\", unit=\"archivo\"):\n",
    "    input_path = os.path.join(audio_processed_train_dir, filename)\n",
    "\n",
    "    try:\n",
    "        print(f\"Procesando {filename}...\")\n",
    "        wav = read_audio(input_path)\n",
    "        speech_timestamps = get_speech_timestamps(wav, model)\n",
    "\n",
    "        audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "        for i, ts in enumerate(speech_timestamps):\n",
    "            start_ms = ts['start'] * 1000 / 16000  # convertir muestras a ms (16kHz)\n",
    "            end_ms = ts['end'] * 1000 / 16000\n",
    "            segment = audio[start_ms:end_ms]\n",
    "            segment.export(os.path.join(output_dir, f\"{filename}_voz_{i+1}.wav\"), format=\"wav\")\n",
    "\n",
    "        print(f\"‚úÖ {len(speech_timestamps)} segmentos guardados para {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error con {filename}: {e}. Saltando...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
